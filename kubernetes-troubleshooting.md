---
layout: default
title: Kubernetes Troubleshooting
nav_order: 3
description: "Kubernetes cluster yÃ¶netimi ve sorun giderme iÃ§in pratik komutlar ve Ã§Ã¶zÃ¼mler"
permalink: /kubernetes-troubleshooting
---

# Kubernetes Troubleshooting Rehberi
{: .no_toc }

Kubernetes cluster yÃ¶netimi ve sorun giderme iÃ§in kapsamlÄ± komut ve Ã§Ã¶zÃ¼m rehberi.
{: .fs-6 .fw-300 }

## Ä°Ã§indekiler
{: .no_toc .text-delta }

1. TOC
{:toc}

---

## ğŸ”§ Node Ä°ÅŸlemleri

### ğŸ”¹ Node'u Klasik YÃ¶ntemle KÃ¼me'ye Ekleme

```bash
kubeadm join <MASTER_IP>:<PORT> --token <TOKEN> --discovery-token-ca-cert-hash sha256:<HASH>
```

- `kubeadm token create --print-join-command` komutuyla master'dan join komutunu alabilirsin.

### ğŸ”¹ Node'un SaÄŸlÄ±ÄŸÄ±nÄ± Kontrol Etme

```bash
kubectl get nodes
kubectl describe node <NODE_ADI>
```

- `NotReady` durumu gÃ¶rÃ¼yorsan genelde `kubelet` ya da `container runtime` Ã§alÄ±ÅŸmÄ±yordur.
- SSH ile nodeâ€™a girip `systemctl status kubelet` ile bak.

### ğŸ”¹ Node'dan Taint KaldÄ±rma

```bash
kubectl taint nodes <NODE_ADI> node-role.kubernetes.io/master-
```

- EÄŸer `NoSchedule` nedeniyle Podâ€™lar bu nodeâ€™a gitmiyorsa bu komutla aÃ§arsÄ±n.

### ğŸ”¹ Nodeâ€™a Taint Ekleme

```bash
kubectl taint nodes <NODE_ADI> key=value:NoSchedule
```

- Podâ€™larÄ±n bu nodeâ€™a gitmesini istemiyorsan (Ã¶rneÄŸin Ã¶zel iÅŸler iÃ§in) kullanÄ±lÄ±r.

## ğŸ”„ Pod Yeniden BaÅŸlatma

```bash
kubectl delete pod <POD_ADI> -n <NAMESPACE>
```

- Deployment varsa otomatik yeniden gelir.
- ConfigMap veya Secret deÄŸiÅŸtiÄŸinde restart gerekebilir.

## ğŸ§¹ Pod Temizleme

```bash
kubectl get pods --all-namespaces | grep Evicted
kubectl delete pod <POD_ADI> -n <NAMESPACE>
```

- Evicted podâ€™lar sistemi kirletir, dÃ¼zenli temizle.

## ğŸ” Pod LoglarÄ±nÄ± Ä°nceleme

```bash
kubectl logs <POD_ADI> -n <NAMESPACE>
kubectl logs <POD_ADI> -c <CONTAINER_ADI> -n <NAMESPACE>
```

- Hata traceâ€™lerini gÃ¶rmek iÃ§in birebir.
- Ã‡ok eski loglar iÃ§in `kubectl logs --previous` kullanÄ±labilir.

## ğŸ” Pod iÃ§inde Komut Ã‡alÄ±ÅŸtÄ±rma

```bash
kubectl exec -it <POD_ADI> -n <NAMESPACE> -- /bin/sh
```

- BazÄ± imajlarda `/bin/bash` yerine `/bin/sh` Ã§alÄ±ÅŸÄ±r.

## ğŸŒ Servis (Service) Problemleri

### ğŸ”¹ Service UlaÅŸÄ±labilirlik Testi

```bash
kubectl get svc -n <NAMESPACE>
kubectl describe svc <SERVICE_ADI> -n <NAMESPACE>
```

- Servis `ClusterIP`, `NodePort`, `LoadBalancer` tiplerinden hangisi?
- Hedef Podâ€™lar gerÃ§ekten ayakta mÄ±?

### ğŸ”¹ DNS Ã‡Ã¶zÃ¼mleme Problemi

```bash
kubectl exec -it <POD_ADI> -- nslookup <SERVICE_ADI>.<NAMESPACE>.svc.cluster.local
```

- CoreDNS problemi olabilir. AÅŸaÄŸÄ±daki gibi yeniden baÅŸlatÄ±labilir:

```bash
kubectl -n kube-system rollout restart deployment coredns
```

## ğŸ“¦ PVC (PersistentVolumeClaim) Problemleri

### ğŸ”¹ PVC DurumlarÄ±nÄ± GÃ¶rÃ¼ntÃ¼leme

```bash
kubectl get pvc -n <NAMESPACE>
kubectl describe pvc <PVC_ADI> -n <NAMESPACE>
```

- `Pending` durumda kalÄ±yorsa uygun StorageClass yok demektir.
- `kubectl get sc` ile mevcut sÄ±nÄ±flarÄ± kontrol et.

## ğŸ’¥ CrashLoopBackOff SorunlarÄ±

### ğŸ”¹ Pod DetaylarÄ±na Bak

```bash
kubectl describe pod <POD_ADI> -n <NAMESPACE>
```

- OlaylarÄ± (Events) incele. Genellikle yanlÄ±ÅŸ environment variable, configmap hatasÄ± Ã§Ä±kar.

### ğŸ”¹ Container LoglarÄ±

```bash
kubectl logs <POD_ADI> --previous -n <NAMESPACE>
```

- `--previous`, Ã§Ã¶ken son containerâ€™Ä±n logunu gÃ¶sterir.

## ğŸš¨ Pod Scheduling Problemleri

```bash
kubectl describe pod <POD_ADI>
```

- `Events` kÄ±smÄ±nda `0/3 nodes are available: 3 Insufficient cpu` gibi mesajlar varsa kaynak yetersiz.
- Yeni node eklemek ya da kaynak limitlerini dÃ¼ÅŸÃ¼rmek gerekebilir.

## ğŸ“¡ LoadBalancer Servis DÄ±ÅŸ IP AlamÄ±yor

```bash
kubectl get svc <SERVICE_ADI>
```

- DÄ±ÅŸ IP gelmiyorsa `cloud controller manager` loglarÄ±na bak.
- `MetalLB` gibi bare-metal Ã§Ã¶zÃ¼mlerde config hatasÄ± olabilir:

```bash
kubectl get configmap -n metallb-system config -o yaml
```

## ğŸš€ Deployment SorunlarÄ±

### ğŸ”¹ Rollout Durumunu Kontrol Et

```bash
kubectl rollout status deployment <DEPLOYMENT_ADI> -n <NAMESPACE>
```

- Deployment takÄ±ldÄ±ysa, yeni imaj Ã§ekilememiÅŸ olabilir. ImagePullBackOff hatasÄ±na dikkat.

### ğŸ”¹ Deploymentâ€™Ä± Geri Alma (Rollback)

```bash
kubectl rollout undo deployment <DEPLOYMENT_ADI> -n <NAMESPACE>
```

- Yeni sÃ¼rÃ¼m sorun Ã§Ä±kardÄ±ysa bir Ã¶nceki haline dÃ¶ner.

## ğŸ› ï¸ ConfigMap SorunlarÄ±

### ğŸ”¹ ConfigMap'i Yeniden YÃ¼klemek

```bash
kubectl create configmap <AD> --from-file=dosya.env -o yaml --dry-run=client | kubectl apply -f -
```

- ConfigMap deÄŸiÅŸti ama Pod hala eski halindeyse Podâ€™u yeniden baÅŸlatmak gerekebilir.

### ğŸ”¹ Pod'da ConfigMapâ€™in YÃ¼klendiÄŸini Kontrol Et

```bash
kubectl exec -it <POD_ADI> -n <NAMESPACE> -- cat /path/in/container/config.env
```

## ğŸ” Secret Problemleri

### ğŸ”¹ Secretâ€™i Okumak (Base64 Decode ile)

```bash
kubectl get secret <SECRET_ADI> -n <NAMESPACE> -o jsonpath="{.data}"
```

- Ã‡Ä±kan deÄŸerler base64 ile encodeâ€™dur.

```bash
echo "cGFzc3dvcmQ=" | base64 -d
```

### ğŸ”¹ Secretâ€™i GÃ¼ncellemek

```bash
kubectl create secret generic <AD> --from-literal=key=value -o yaml --dry-run=client | kubectl apply -f -
```

## ğŸ§  FaydalÄ± `kubectl` KÄ±sayollarÄ±

### ğŸ”¹ Etiketle Node veya Pod

```bash
kubectl label nodes <NODE_ADI> zone=istanbul
kubectl label pods <POD_ADI> env=prod
```

### ğŸ”¹ KaynaklarÄ± Etiket ile Filtrele

```bash
kubectl get pods -l env=prod
```

### ğŸ”¹ SÄ±k KullanÄ±lan `kubectl` KÄ±sa Kodu

```bash
kubectl get all -n <NAMESPACE>
```

- TÃ¼m kaynaklarÄ± (pod, svc, deploy vs) bir anda listeler.

## ğŸ” NetworkPolicy SorunlarÄ±

### ğŸ”¹ Pod'lar ArasÄ± EriÅŸim Engelleniyor

```bash
kubectl get networkpolicy -n <NAMESPACE>
kubectl describe networkpolicy <POLICY_ADI> -n <NAMESPACE>
```

- EriÅŸim engellenmiÅŸse `allow all` politikasÄ± test iÃ§in yazÄ±labilir:

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-all
  namespace: default
spec:
  podSelector: {}
  ingress:
    - {}
  egress:
    - {}
  policyTypes:
    - Ingress
    - Egress
```

## âš™ï¸ Helm SorunlarÄ±

### ğŸ”¹ Helm Releaseâ€™leri GÃ¶rÃ¼ntÃ¼leme

```bash
helm list -A
```

- TÃ¼m namespace'lerdeki releaseâ€™leri gÃ¶sterir.

### ğŸ”¹ Helm ile Kurulu KaynaÄŸÄ± Silmek

```bash
helm uninstall <RELEASE_ADI> -n <NAMESPACE>
```

- Helm ile kuruluysa `kubectl delete` ile silmek eksik temizlik yapabilir.

## ğŸŒ Ingress Problemleri

### ğŸ”¹ Ingress KaynaklarÄ±nÄ± GÃ¶rmek

```bash
kubectl get ingress -A
```

- IP/hostname Ã§Ã¶zÃ¼lmÃ¼yorsa DNS kaydÄ± eksik olabilir.
- Ingress controller (Ã¶rneÄŸin nginx) Ã§alÄ±ÅŸÄ±yor mu?

```bash
kubectl get pods -n ingress-nginx
```

## ğŸ“Š Metrics Server SorunlarÄ±

### ğŸ”¹ `kubectl top` Ã‡alÄ±ÅŸmÄ±yor

```bash
kubectl top nodes
```

- Hata alÄ±yorsan Metrics Server kurulu deÄŸil demektir.
- Kurulum sonrasÄ± `--kubelet-insecure-tls` parametresi gerekebilir:

```bash
--kubelet-insecure-tls
```

### ğŸ”¹ Metrics Server Pod LoglarÄ±na Bak

```bash
kubectl logs <POD_ADI> -n kube-system
```

## ğŸ“ Pod ile Dosya Transferi (kubectl cp)

### ğŸ”¹ Pod'dan Host'a Dosya Kopyalama

```bash
kubectl cp <NAMESPACE>/<POD_ADI>:/path/in/container /local/path
```

### ğŸ”¹ Hostâ€™tan Podâ€™a Dosya Kopyalama

```bash
kubectl cp /local/path <NAMESPACE>/<POD_ADI>:/path/in/container
```

- Pod Ã§alÄ±ÅŸÄ±r durumda olmalÄ±. Hedef yol mevcut deÄŸilse hata verir.

## ğŸ§¬ etcd Backup ve Geri YÃ¼kleme

### ğŸ”¹ etcd YedeÄŸi Alma (Kubeadm KurulumlarÄ± Ä°Ã§in)

```bash
ETCDCTL_API=3 etcdctl snapshot save snapshot.db   --endpoints=https://127.0.0.1:2379   --cacert=/etc/kubernetes/pki/etcd/ca.crt   --cert=/etc/kubernetes/pki/etcd/server.crt   --key=/etc/kubernetes/pki/etcd/server.key
```

### ğŸ”¹ etcd YedeÄŸi Geri YÃ¼kleme

```bash
ETCDCTL_API=3 etcdctl snapshot restore snapshot.db   --data-dir=/var/lib/etcd-from-backup
```

- Dikkat: Mevcut etcd klasÃ¶rÃ¼nÃ¼ yedekleyip kapatmadan restore yapma.

## âš™ï¸ Kube-Proxy Problemleri

### ğŸ”¹ Kube-Proxy LoglarÄ±nÄ± Ä°ncele

```bash
kubectl -n kube-system logs -l k8s-app=kube-proxy
```

- Servis routing problemi varsa burada ipucu bulabilirsin.

### ğŸ”¹ iptables KurallarÄ± DoÄŸru mu?

```bash
iptables -t nat -L -n | grep KUBE
```

- Kube-proxy `iptables` modundayken bu kurallarÄ± yazar. Eksikse proxy Ã§alÄ±ÅŸmÄ±yor olabilir.

## ğŸ§© CNI (Container Network Interface) SorunlarÄ±

### ğŸ”¹ Podâ€™lar ArasÄ± EriÅŸim Yoksa

- `kubectl get pods -o wide` ile IPâ€™leri kontrol et.
- CNI plugin (Flannel, Calico, vs.) podlarÄ± Ã§alÄ±ÅŸÄ±yor mu?

```bash
kubectl get pods -n kube-system
```

### ğŸ”¹ Yeni Node Ekledin, Ama Podâ€™lar IP AlmÄ±yor

- CNI plugin node Ã¼zerinde dÃ¼zgÃ¼n yÃ¼klenmemiÅŸ olabilir.
- Nodeâ€™da aÅŸaÄŸÄ±dakileri kontrol et:

```bash
ls /etc/cni/net.d/
```

## ğŸŒ CoreDNS SorunlarÄ±

### ğŸ”¹ CoreDNS Podâ€™larÄ±nÄ± GÃ¶rÃ¼ntÃ¼le

```bash
kubectl get pods -n kube-system -l k8s-app=kube-dns
```

- `CrashLoopBackOff` durumundaysa `ConfigMap` hatalÄ± olabilir:

```bash
kubectl -n kube-system edit configmap coredns
```

## ğŸ”’ API Server UlaÅŸÄ±labilirlik

### ğŸ”¹ Apiserver Durumu

```bash
kubectl get componentstatuses
```

- `etcd`, `scheduler`, `controller-manager`, `apiserver` buradan izlenebilir.

### ğŸ”¹ API Server LoglarÄ±

```bash
journalctl -u kube-apiserver
```

- Hata durumlarÄ±nda burada detaylÄ± log bulursun.

## ğŸ§  Kubelet SorunlarÄ±

### ğŸ”¹ Kubelet Hizmeti Ã‡alÄ±ÅŸÄ±yor mu?

```bash
systemctl status kubelet
```

- `Failed` ise genellikle yanlÄ±ÅŸ config veya `/etc/kubernetes/kubelet.conf` dosyasÄ± bozulmuÅŸtur.

### ğŸ”¹ Kubelet LoglarÄ±

```bash
journalctl -u kubelet
```

## ğŸ”¥ DÃ¼ÅŸÃ¼k Seviyeli Network Problemleri

### ğŸ”¹ iptables ya da ipvs DoÄŸrulama

```bash
iptables-save | grep KUBE
ipvsadm -Ln
```

- Pod'lara trafik yÃ¶nlenmiyorsa burada sÄ±kÄ±ntÄ± olabilir.

## ğŸ“ GÃ¼nlÃ¼k KayÄ±tlarÄ± (systemd journal)

### ğŸ”¹ Belirli SÃ¼re Ä°Ã§in KayÄ±tlarÄ± GÃ¶rÃ¼ntÃ¼le

```bash
journalctl -u kubelet --since "2 hours ago"
```

### ğŸ”¹ En Son KayÄ±tlarÄ± CanlÄ± Takip Etmek

```bash
journalctl -u kubelet -f
```

## ğŸ“¥ Log Toplama & Ä°nceleme

### ğŸ”¹ Namespace BazlÄ± TÃ¼m Pod LoglarÄ±

```bash
for pod in $(kubectl get pods -n <NAMESPACE> -o jsonpath="{.items[*].metadata.name}"); do
  echo "== $pod ==";
  kubectl logs $pod -n <NAMESPACE>;
done
```

- GeniÅŸ hata taramasÄ± iÃ§in faydalÄ±.

### ğŸ”¹ Crashloop OlaylarÄ±nÄ± Ã‡ekmek

```bash
kubectl get events --all-namespaces | grep -i crash
```

## â›” Node Drain & Cordoning

### ğŸ”¹ Node Drain (Pod'larÄ± TaÅŸÄ±yarak BoÅŸaltma)

```bash
kubectl drain <NODE_ADI> --ignore-daemonsets --delete-emptydir-data
```

- Genelde bakÄ±m veya silme Ã¶ncesi yapÄ±lÄ±r.
- StatefulSet varsa dikkatli olunmalÄ±, veri kaybÄ± yaÅŸanabilir.

### ğŸ”¹ Node'u Schedulingâ€™e Kapatmak

```bash
kubectl cordon <NODE_ADI>
```

### ğŸ”¹ Node Schedulingâ€™i AÃ§mak

```bash
kubectl uncordon <NODE_ADI>
```

## ğŸ§± TakÄ±lÄ± KalmÄ±ÅŸ PVC/PV Problemleri

### ğŸ”¹ PVC `Terminating` Durumunda KalÄ±yor

```bash
kubectl get pvc -n <NAMESPACE>
```

- Finalizerâ€™Ä± temizlemek gerekebilir:

```bash
kubectl patch pvc <PVC_ADI> -n <NAMESPACE> -p '{"metadata":{"finalizers":null}}'
```

### ğŸ”¹ PV `Released` Durumunda KalÄ±yor

- ManÃ¼el olarak temizlenmeli ya da reclaim policy `Retain` ise silinip yeniden oluÅŸturulmalÄ±.

## ğŸ§² Pod Affinity / Anti-Affinity SorunlarÄ±

### ğŸ”¹ Scheduling Neden Olmuyor?

```bash
kubectl describe pod <POD_ADI>
```

- `MatchExpressions` veya `requiredDuringSchedulingIgnoredDuringExecution` kurallarÄ± hatalÄ± olabilir.
- Etiket uyuÅŸmazlÄ±ÄŸÄ± varsa `0/3 nodes match pod affinity rules` ÅŸeklinde uyarÄ± verir.

## â¬†ï¸ Upgrade SonrasÄ± Sorunlar

### ğŸ”¹ API Version Deprecated (Ã–rneÄŸin apps/v1beta1)

```bash
kubectl get deploy -o yaml | grep apiVersion
```

- API deÄŸiÅŸikliklerinde Ã¶nce tÃ¼m CRD ve manifest'ler yeni versiyona uyumlu hale getirilmeli.

### ğŸ”¹ CoreDNS, kube-proxy veya CNI UyuÅŸmazlÄ±klarÄ±

- `kubectl get ds -n kube-system` ile `DaemonSet` durumlarÄ±nÄ± kontrol et.
- Yeni versiyona uygun imaj tagâ€™leri kullanÄ±ldÄ±ÄŸÄ±ndan emin olun.

## ğŸ§© Custom Resource Definition (CRD) SorunlarÄ±

### ğŸ”¹ CRDâ€™yi Listele ve DetaylarÄ±nÄ± GÃ¶r

```bash
kubectl get crd
kubectl describe crd <CRD_ADI>
```

- CRD eksikse ona baÄŸlÄ± controller Ã§alÄ±ÅŸmaz.
- CRD versiyonu (v1beta1 vs v1) uyumsuzluÄŸu problem yaratabilir.

### ğŸ”¹ CRD ile OluÅŸturulan Kaynaklar

```bash
kubectl get <KAYNAK_TÃœRÃœ> -n <NAMESPACE>
```

- Ã–rneÄŸin: `kubectl get prometheuses.monitoring.coreos.com -n monitoring`

## ğŸ”” Mutating/Validating Webhook SorunlarÄ±

### ğŸ”¹ Webhookâ€™lar Neden Sorun Ã‡Ä±karÄ±r?

- API server webhookâ€™a ulaÅŸamazsa Pod yaratma iÅŸlemi takÄ±lÄ±r.
- TLS sertifikasÄ± geÃ§ersizse `x509: certificate signed by unknown authority` hatasÄ± Ã§Ä±kar.

### ğŸ”¹ Webhookâ€™larÄ± Listele

```bash
kubectl get mutatingwebhookconfigurations
kubectl get validatingwebhookconfigurations
```

- Detay iÃ§in `kubectl describe` kullan.

### ğŸ”¹ Webhookâ€™u GeÃ§ici Olarak Devre DÄ±ÅŸÄ± BÄ±rak

```bash
kubectl delete mutatingwebhookconfiguration <ADI>
```

- Acil Ã§Ã¶zÃ¼m iÃ§in geÃ§ici bir yaklaÅŸÄ±mdÄ±r.

## ğŸ” RBAC Problemleri

### ğŸ”¹ KullanÄ±cÄ±/POD Yetkisini Test Etme

```bash
kubectl auth can-i get pods --as=some-user -n <NAMESPACE>
```

- EriÅŸim verilmemiÅŸse `no` sonucu dÃ¶ner.

### ğŸ”¹ Role ve RoleBinding KontrolÃ¼

```bash
kubectl get role,rolebinding -n <NAMESPACE>
```

- Cluster-wide iÃ§in `clusterrole` ve `clusterrolebinding` bakÄ±lÄ±r.

## ğŸ“ Audit Log Problemleri (Kube-apiserver)

### ğŸ”¹ Audit Log Etkin mi?

- API sunucusu baÅŸlatÄ±lÄ±rken `--audit-log-path` ve `--audit-policy-file` parametreleri verilmiÅŸ mi?
- Dosya sisteminde audit log var mÄ±?

```bash
cat /var/log/kubernetes/audit.log | grep <USER_ADI>
```

## ğŸ›¡ï¸ Pod GÃ¼venlik AyarlarÄ±

### ğŸ”¹ SecurityContext KontrolÃ¼

```yaml
securityContext:
  runAsUser: 1000
  runAsGroup: 3000
  readOnlyRootFilesystem: true
  allowPrivilegeEscalation: false
```

- Containerâ€™larÄ±n root yetkisi olmamasÄ± iÃ§in Ã¶nemlidir.

### ğŸ”¹ PodSecurityPolicy (Deprecated) Yerine OPA/Gatekeeper

- Kubernetes v1.25 sonrasÄ± PSP kaldÄ±rÄ±ldÄ±.
- Yerine Gatekeeper veya Kyverno gibi policy engineleri kullanÄ±lÄ±r.

## ğŸ§¬ etcd SorunlarÄ±

### ğŸ”¹ etcd Durumu ve Ãœyeler

```bash
ETCDCTL_API=3 etcdctl member list   --endpoints=https://127.0.0.1:2379   --cacert=/etc/kubernetes/pki/etcd/ca.crt   --cert=/etc/kubernetes/pki/etcd/server.crt   --key=/etc/kubernetes/pki/etcd/server.key
```

- Bir node eriÅŸilemiyorsa quorum kaybÄ± olabilir (3 Ã¼yeli cluster iÃ§in en az 2 eriÅŸilebilir olmalÄ±).

### ğŸ”¹ etcd Snapshot Yedekten Geri YÃ¼klemek

```bash
ETCDCTL_API=3 etcdctl snapshot restore snapshot.db   --data-dir=/var/lib/etcd-from-backup
```

- Geri yÃ¼kleme sonrasÄ± static pod manifest dosyasÄ± (`/etc/kubernetes/manifests/etcd.yaml`) bu dizine gÃ¶re gÃ¼ncellenmeli.

## ğŸ“… Sertifika SÃ¼releri ve Yenileme

### ğŸ”¹ Sertifika SÃ¼relerini Kontrol Etme

```bash
kubeadm certs check-expiration
```

- Kubernetes bileÅŸenleri genellikle 1 yÄ±l geÃ§erli sertifikalarla baÅŸlatÄ±lÄ±r.

### ğŸ”¹ TÃ¼m SertifikalarÄ± Yenilemek

```bash
kubeadm certs renew all
systemctl restart kubelet
```

- ArdÄ±ndan kube-apiserver, controller, scheduler vs. restart olur.

## ğŸ§¹ `kubeadm reset` SonrasÄ± Temizlik

### ğŸ”¹ `reset` Komutu

```bash
kubeadm reset
```

- ArdÄ±ndan iptables ve CNI kalÄ±ntÄ±larÄ± temizlenmeli:

```bash
iptables -F && iptables -t nat -F && iptables -t mangle -F && iptables -X
rm -rf /etc/cni/net.d
```

- Yeni `kubeadm init` Ã¶ncesi bu adÄ±m Ã¶nemlidir.

## âš ï¸ Control Plane Failover (HA Ortamlar)

### ğŸ”¹ API Server UlaÅŸÄ±lmÄ±yor

- TÃ¼m control-plane nodeâ€™larÄ± down olduysa quorum kaybÄ± olabilir.
- Load balancer varsa altÄ±ndaki nodeâ€™lar kontrol edilmeli.

### ğŸ”¹ etcd YedeÄŸi Yoksa Tek Noda DÃ¶nme (Tehlikeli)

- YalnÄ±zca bir `etcd` datasÄ± kalan node varsa `--force-new-cluster` ile yeniden baÅŸlatma yapÄ±labilir.
- DÄ°KKAT: Bu yÃ¶ntem diÄŸer Ã¼yelerle uyumsuzluk yaratÄ±r, en son Ã§are olarak kullanÄ±lmalÄ±.
